{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\nimport os\nfor dirname, _, filenames in os.walk('../input/pokemon/Pokemon.csv'): #giving of whats including in the pokemon file\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \ndata = pd.read_csv('../input/pokemon/Pokemon.csv') #adding characteristic attributes table of pokemon game \ndata.head() #returning rows of table values \n\ndata.info() #giving summary of data frame about index type and column types, non null values and memory usage\n\ndata.corr() #Giving pairwise correlation of all columns in data frame\n\nf,ax = plt.subplots(figsize=(18, 18))\nsns.heatmap(data.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax) #creating a corelation map/table.\n                                         #it means showing correlation coefficients between variables.\n                                        #this matrix is used to summarize the data for more advanced analysis\n        \nplt.show() #Plotting from a script\n\ndata.head(10) #returning first 10 row in data frame\n\ndata.columns #giving columns name in data frame with in array\n\n\n\n#MATPLOTLIB\n\ndata.Speed.plot(kind = 'line', color = 'g',label = 'Speed',linewidth=1,alpha = 0.5,grid = True,linestyle = ':') \n                                                                            #taking the datas of speed attribute\ndata.Defense.plot(color = 'r',label = 'Defense',linewidth=1, alpha = 0.5,grid = True,linestyle = '-.') \n                                                                #taking the datas of defense attribute\nplt.legend(loc='upper right')     # legend = puts label into plot\nplt.xlabel('x axis')              # label = name of label\nplt.ylabel('y axis')\nplt.title('Line Plot')            # title = title of plot\nplt.show() #plotting of line plot\n\ndata.plot(kind='scatter', x='Attack', y='Defense',alpha = 0.5,color = 'red')\n#creating of scatter plot\n#identifying of plot kind and determining which attributes will be on x and y plane\nplt.xlabel('Attack')    #writing of x plane name\nplt.ylabel('Defence')   #writing of y plane name\nplt.title('Attack Defense Scatter Plot')  #writing of title name           \n\ndata.Speed.plot(kind = 'hist',bins = 50,figsize = (12,12)) #creating a histogram\nplt.show()\n\ndata.Speed.plot(kind = 'hist',bins = 50)\nplt.clf() #clear the figure with axes\n\n#DICTIONARY \n\ndictionary = {'spain' : 'madrid','usa' : 'vegas'} #creating a dictionary\nprint(dictionary.keys()) #showig of keys in order to insertion sort\nprint(dictionary.values()) #showig of values in order to insertion sort\n\ndictionary['spain'] = \"barcelona\"    #updating of spain key's value\nprint(dictionary)\ndictionary['france'] = \"paris\"       #adding new entry\nprint(dictionary)\ndel dictionary['spain']              #removing the entry of spain key\nprint(dictionary)\nprint('france' in dictionary)        #if the france entry is in the dictionary, returning true\ndictionary.clear()                   #clearing of dictionary\nprint(dictionary)                    #printing an empty dictionary\n\n\n#PANDAS\n\ndata = pd.read_csv('../input/pokemon/Pokemon.csv')\n\nseries = data['Defense']        # data['Defense'] = series\nprint(type(series))             #returns class type of the argument as parameter\ndata_frame = data[['Defense']]  # data[['Defense']] = data frame\nprint(type(data_frame))\n\nprint(3 > 2) #returns true\nprint(3!=2)  #returns false\n# Boolean operators\nprint(True and False) #returns false because both of them aren't same\nprint(True or False)  #returns true\n\nx = data['Defense']>200    #finding of which attiributes defense value are higher than 200 which means three\ndata[x]                    #list created of '[]' in this square brackets, so using this one for giving the results\n\ndata[np.logical_and(data['Defense']>200, data['Attack']>100 )] #in here comparising of two values together using by 'np.logical_and'\n\ndata[(data['Defense']>200) & (data['Attack']>100)] #'&' this operation doing same action of 'np.logical_and'\n\n\n#WHILE and FOR LOOPS\n\ni = 0\nwhile i != 5 :\n    print('i is: ',i)\n    i +=1\nprint(i,' is equal to 5') #printing all values one by one until i equal to 5\n\nlis = [1,2,3,4,5]\nfor i in lis:\n    print('i is: ',i)\nprint('')              #firstly the list created, then with for loop printing all values one by one\n\nfor index, value in enumerate(lis):\n    print(index,\" : \",value)\nprint('')   #sorting the values with index item\n\ndictionary = {'spain':'madrid','france':'paris'}\nfor key,value in dictionary.items():\n    print(key,\" : \",value)\nprint('')  #also doing this in dictionaries with changing the for variables\n\nfor index,value in data[['Attack']][0:1].iterrows():\n    print(index,\" : \",value) #using for loop with taking the values of data frame\n    \n    \n\n#USER DEFINED FUNCTION\n\n\ndef tuple_ex(): #defining tuple function\n    t = (1,2,3) #adding variables\n    return t\na,b,c = tuple_ex()\nprint(a,b,c)       #printing whats in the tuple function\n\n\n\n#SCOPE\n\nx = 2\ndef f():\n    x = 3\n    return x\nprint(x)      \nprint(f()) #these are examples of how we can calling the global and local scope\n\nx = 5\ndef f():\n    y = 2*x        \n    return y\nprint(f())    #examples of doing arithmetic operations\n\nimport builtins\ndir(builtins)    #it means direct access to all built in identifiers\n\n\n#NESTED FUNCTION\n\n\ndef square():\n    \"\"\" return square of value \"\"\"\n    def add():\n        \"\"\" add two local variable \"\"\"\n        x = 2\n        y = 3\n        z = x + y\n        return z\n    return add()**2\nprint(square())     #example inside functions, square a variable\n\n#DEFAULT and FLEXIBLE ARGUMENTS\n\ndef f(a, b = 1, c = 2):\n    y = a + b + c\n    return y\nprint(f(5)) #in here giving value of a variable\nprint(f(5,4,3)) #changing variable values for each  of them\n\ndef f(*args):\n    for i in args:\n        print(i)\nf(1)  \nprint(\"\")\nf(1,2,3,4)   #in flexible arguments don't need to giving values in function as defining \n\ndef f(**kwargs):\n    for key, value in kwargs.items():               \n        print(key, \" \", value)\nf(country = 'spain', capital = 'madrid', population = 123456) #using flexible arguments with dictionary and returning the variables as a loop\n\n\n#LAMBDA FUNCTION\n\n\nsquare = lambda x: x**2     \nprint(square(4))\ntot = lambda x,y,z: x+y+z   \nprint(tot(1,2,3))          #with lambda writing everything in one line\n\n\nnumber_list = [1,2,3]\ny = map(lambda x:x**2,number_list)\nprint(list(y))            #with this returning more than one result\n\n\n#ITERATORS\n\nname = \"ronaldo\"\nit = iter(name)\nprint(next(it))    \nprint(*it)       #taking exact needed string value\n\n\n\nlist1 = [1,2,3,4]\nlist2 = [5,6,7,8]\nz = zip(list1,list2)\nprint(z)\nz_list = list(z)\nprint(z_list)     #matching two list one by one \n\n\nun_zip = zip(*z_list)\nun_list1,un_list2 = list(un_zip) \nprint(un_list1)\nprint(un_list2)\nprint(type(un_list2))  #seperating of zip functions\n\n\n#LIST COMPREHENSİON\n\nnum1 = [1,2,3]\nnum2 = [i + 1 for i in num1 ]\nprint(num2) #adding 1 to each of them using a list \n\n\nnum1 = [5,10,15]\nnum2 = [i**2 if i == 10 else i-5 if i < 7 else i+5 for i in num1]\nprint(num2)  \n\nnum1 = [5,10,15]\nnum2 = [i**2 if i == 10 else i-5 if i < 7 else i+5 for i in num1]\nprint(num2)  #also lists can be used for conditionals\n\nthreshold = sum(data.Speed)/len(data.Speed)\ndata[\"speed_level\"] = [\"high\" if i > threshold else \"low\" for i in data.Speed]\ndata.loc[:10,[\"speed_level\",\"Speed\"]]\n\n\n#DIAGNOSE DATA for CLEANING\n\n\ndata = pd.read_csv('../input/pokemon/Pokemon.csv')\ndata.head()  #head using for first 5 row\n\ndata.tail() #tail using for last 5 row\n\ndata.columns #gives column names\n\ndata.shape #how much rows and columns included in table\n\ndata.info() #giving every kind of info in table like dataframe, number of sample or row, number of feature or column, feature types and memory usage\n\n#EXPLORATORY DATA ANALYSIS\n\nprint(data['Type 1'].value_counts(dropna =False)) #seeing and comparing values in table\n\n1,2,3,4,200\n\ndata.describe() #does not return the null values and with this one describing which of them is max one and min one\n\n\n#VISUAL EXPLORATORY DATA ANALYSIS\n\ndata.boxplot(column='Attack',by = 'Legendary') #A boxplot is a standardized way of displaying the distribution of data based on a five number summary (“minimum”, first quartile (Q1), median, third quartile (Q3), and “maximum”).\n\n\n#TIDY DATA\n\ndata_new = data.head()   #defining a simple table because just want to make comparision with these ones.\ndata_new\n\nmelted = pd.melt(frame=data_new,id_vars = 'Name', value_vars= ['Attack','Defense'])\nmelted #making different kind of comparison, giving values one by one\n\n\n#PIVOTING DATA\n\nmelted.pivot(index = 'Name', columns = 'variable',values='value') #this one using for two values with together\n\n\n#CONCATENATING DATA\n\ndata1 = data.head()\ndata2= data.tail()\nconc_data_row = pd.concat([data1,data2],axis =0,ignore_index =True) \nconc_data_row  #concatenating two tables in one table\n\ndata1 = data['Attack'].head()\ndata2= data['Defense'].head()\nconc_data_col = pd.concat([data1,data2],axis =1) # axis = 1 : adds dataframes in column\nconc_data_col  #concatenating two columns\n\n\n#DATA TYPES\n\ndata.dtypes #in table gives us the columns data types\n\ndata['Type 1'] = data['Type 1'].astype('category')\ndata['Speed'] = data['Speed'].astype('float')       #changing of data types\n\ndata.dtypes\n\n\n#MISSING DATA and TESTING WITH ASSERT\n\ndata.info()\n\ndata[\"Type 2\"].value_counts(dropna =False) #gives us unique values\n\ndata1=data   \ndata1[\"Type 2\"].dropna(inplace = True)\nassert 1==1  #assert keyword is using for debugging code\n\n\n#BUILDING DATA FRAMES FROM SCRATCH\n\ncountry = [\"Spain\",\"France\"] \npopulation = [\"11\",\"12\"]      #adding columns in table\nlist_label = [\"country\",\"population\"] #giving names to those ones\nlist_col = [country,population]\nzipped = list(zip(list_label,list_col))  #connecting rows and columns\ndata_dict = dict(zipped)\ndf = pd.DataFrame(data_dict) \ndf\n\ndf[\"capital\"] = [\"madrid\",\"paris\"] #adding new column in table\ndf\n\ndf[\"income\"] = 0 #every country's people income arrange to 0\ndf\n\n#VISUAL EXPLORATORY DATA ANALYSIS\n\n\ndata1 = data.loc[:,[\"Attack\",\"Defense\",\"Speed\"]] #making a confusing,giving all values together\ndata1.plot() \n\ndata1.plot(subplots = True) #with subplot giving plots separately\nplt.show() \n\ndata1.plot(kind = \"scatter\",x=\"Attack\",y = \"Defense\") #scatter plot uses dots to represent individual pieces of data\nplt.show()\n\ndata1.plot(kind = \"hist\",y = \"Defense\",bins = 50,range= (0,250),normed = True) #making a histogram plot and arranging of bar length\n\nfig, axes = plt.subplots(nrows=2,ncols=1)\ndata1.plot(kind = \"hist\",y = \"Defense\",bins = 50,range= (0,250),normed = True,ax = axes[0])\ndata1.plot(kind = \"hist\",y = \"Defense\",bins = 50,range= (0,250),normed = True,ax = axes[1],cumulative = True) #cumulative histogram created\nplt.savefig('graph.png')\nplt\n\n\n#STATISTICAL EXPLORATORY DATA ANALYSIS\n\ndata.describe()\n\n\n#INDEXING PANDAS TIME SERIES\n\ntime_list = [\"1992-03-08\",\"1992-04-12\"]\nprint(type(time_list[1])) #showing the type of time as a string\n\ndatetime_object = pd.to_datetime(time_list) #changing it as a object\nprint(type(datetime_object))\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ndata2 = data.head()\ndate_list = [\"1992-01-10\",\"1992-02-10\",\"1992-03-10\",\"1993-03-15\",\"1993-03-16\"]\ndatetime_object = pd.to_datetime(date_list)\ndata2[\"date\"] = datetime_object   #adding dates first column of the table and and arranging them which ones date time higher than others\n\ndata2= data2.set_index(\"date\")\ndata2\n\nprint(data2.loc[\"1993-03-16\"])\nprint(data2.loc[\"1992-03-10\":\"1993-03-16\"]) #giving datas just between these two dates which are 3 column\n\n\n#RESAMPLING PANDAS TIME SERIES\n\ndata2.resample(\"A\").mean() #with resample giving specific string value for each of them (year,month,day) \n                          #in here sorting them as a year lowest to highest\n    \ndata2.resample(\"M\").mean() #sorting them as a month lowest to highest with using resample\ndata2.resample(\"M\").first().interpolate(\"linear\") # all missing read values are filled with NaNs\n\ndata2.resample(\"M\").mean().interpolate(\"linear\")  #jumping of missing values\n\n\n#MANIPULATING DATA FRAMES WITH PANDAS\n\ndata = pd.read_csv('../input/pokemon/Pokemon.csv')\ndata= data.set_index(\"#\")\ndata.head() #taking the first 5 rows in table\n\ndata[\"HP\"][1] #gives the value of hp column first line\n\ndata.HP[1] #doing same thing with using dot also\n\ndata.loc[1,[\"HP\"]] #loc gives the index label and data type\n\ndata[[\"HP\",\"Attack\"]] #choosing of particular columns\n\n\n#SLICING DATA FRAME\n\nprint(type(data[\"HP\"]))     # series\nprint(type(data[[\"HP\"]]))   # data frames\n\ndata.loc[1:10,\"HP\":\"Defense\"] #gives the columns of 1 to 10\n\ndata.loc[10:1:-1,\"HP\":\"Defense\"]  #gives the columns of 1 to 10 but writing them reversly\n\ndata.loc[1:10,\"Speed\":] #begins of speed column to end of the columns\n\n#FILTERING DATA FRAMES\n\nboolean = data.HP > 200\ndata[boolean]            #creating a boolean series and retuns the table with condition\n\nfirst_filter = data.HP > 150\nsecond_filter = data.Speed > 35\ndata[first_filter & second_filter] #combining of two filter together and the result has to supply each of them\n\ndata.HP[data.Speed<15] \n\n\n#TRANSFORMING DATA\n\ndef div(n):\n    return n/2\ndata.HP.apply(div) #dividing of each column in HP \n\ndata.HP.apply(lambda n : n/2) #also with lambda can do dividing too\n\ndata[\"total_power\"] = data.Attack + data.Defense\ndata.head() #adding a new column end of the all columns and in here putting of adding operations one by one\n\n\n#INDEX OBJECTS AND LABELED DATA\n\nprint(data.index.name)\n\ndata.index.name = \"index_name\"\ndata.head()\n\ndata.head()\ndata3 = data.copy() #copying data table first 5 rows on a new table which is data 3\n\ndata3.index = range(100,900,1)\ndata3.head()\n\n\n#HIERARCHICAL INDEXING\n\ndata = pd.read_csv('../input/pokemon/Pokemon.csv')\ndata.head() \n\ndata1 = data.set_index([\"Type 1\",\"Type 2\"]) \ndata1.head(100)  #seperating by type1 and putting the type2 values in it\n\n#PIVOTING DATA FRAMES\n\ndic = {\"treatment\":[\"A\",\"A\",\"B\",\"B\"],\"gender\":[\"F\",\"M\",\"F\",\"M\"],\"response\":[10,45,5,9],\"age\":[15,4,72,65]}\ndf = pd.DataFrame(dic)\ndf                     #creating a new table\n\ndf.pivot(index=\"treatment\",columns = \"gender\",values=\"response\") #changing the position\n\n#STACKING and UNSTACKING DATAFRAME\n\ndf1 = df.set_index([\"treatment\",\"gender\"])\ndf1  #treatment is outer, gender is inner\n\ndf1.unstack(level=0) #giving just first lines for each column\n\ndf1.unstack(level=1) #giving second lines for each column\n\ndf2 = df1.swaplevel(0,1) #changing of columns positions\ndf2\n\n\n#MELTING DATA FRAMES\n\ndf\npd.melt(df,id_vars=\"treatment\",value_vars=[\"age\",\"response\"]) # df.pivot(index=\"treatment\",columns = \"gender\",values=\"response\")\n\n#CATEGORICALS AND GROUPBY\n\ndf\ndf.groupby(\"treatment\").mean() #mean using for average of same column\n\ndf.groupby(\"treatment\").age.max() #finding the max age\n\ndf.groupby(\"treatment\")[[\"age\",\"response\"]].min() #finding the min values of age and response columns seperately and grouping them\n\ndf.info()\n\n\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-02T14:00:07.765861Z","iopub.execute_input":"2022-03-02T14:00:07.766192Z","iopub.status.idle":"2022-03-02T14:00:09.746123Z","shell.execute_reply.started":"2022-03-02T14:00:07.766157Z","shell.execute_reply":"2022-03-02T14:00:09.745124Z"},"trusted":true},"execution_count":22,"outputs":[]}]}